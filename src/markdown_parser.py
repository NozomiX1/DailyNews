# DailyNews - Markdown è§£ææ¨¡å—
# å°†å¾®ä¿¡å…¬ä¼—å·æ–‡ç«  HTML è½¬æ¢ä¸º Markdown
import requests
from bs4 import BeautifulSoup
from markdownify import markdownify as md
import re
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
import config

# æ²¿ç”¨é…ç½®ä¸­çš„ Headers
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Cookie": config.COOKIE
}


def parse_wechat_to_md(url):
    """
    ä¸‹è½½å¾®ä¿¡æ–‡ç« å¹¶è½¬æ¢ä¸º Markdown

    Args:
        url: å¾®ä¿¡æ–‡ç« é“¾æ¥

    Returns:
        Markdown æ ¼å¼çš„æ–‡ç« å†…å®¹ï¼Œå¤±è´¥è¿”å› None
    """
    print(f"    ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
    try:
        resp = requests.get(url, headers=HEADERS, timeout=30)
        if resp.status_code != 200:
            print(f"    âŒ ä¸‹è½½å¤±è´¥: {resp.status_code}")
            return None

        # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆå†…å®¹
        if 'js_content' not in resp.text:
            print(f"    âŒ Cookie å¯èƒ½å·²è¿‡æœŸæˆ–æ— æ•ˆ")
            return None

        soup = BeautifulSoup(resp.text, 'html.parser')

        # ================= 1. æå–å…ƒæ•°æ® =================

        # æ ‡é¢˜
        title_tag = soup.find(id="activity-name")
        title = title_tag.get_text(strip=True) if title_tag else "æ— æ ‡é¢˜"

        # å…¬ä¼—å·åç§°
        account_tag = soup.find(id="js_name")
        account = account_tag.get_text(strip=True) if account_tag else "æœªçŸ¥å…¬ä¼—å·"

        # æå–æ—¶é—´
        date_str = ""
        scripts = soup.find_all("script")
        for script in scripts:
            if script.string and "ct =" in script.string:
                match = re.search(r'ct\s*=\s*"(\d+)"', script.string)
                if match:
                    import time
                    ts = int(match.group(1))
                    date_str = time.strftime("%Y-%m-%d %H:%M", time.localtime(ts))
                    break

        # ================= 2. æå–æ­£æ–‡ =================

        content_div = soup.find('div', {'id': 'js_content'})
        if not content_div:
            content_div = soup.find('div', {'class': 'rich_media_content'})

        if not content_div:
            return None

        # ä¿®å¤å›¾ç‰‡ï¼šdata-src -> src
        for img in content_div.find_all('img'):
            if 'data-src' in img.attrs:
                img['src'] = img['data-src']
            if 'style' in img.attrs:
                del img['style']

        # ç§»é™¤é‡å¤çš„ logo å›¾ç‰‡
        from collections import Counter
        img_urls = [img.get('src') or img.get('data-src', '')
                    for img in content_div.find_all('img')
                    if img.get('src') or img.get('data-src')]
        url_counts = Counter(img_urls)

        for img in content_div.find_all('img'):
            img_url = img.get('src') or img.get('data-src', '')
            if img_url and url_counts.get(img_url, 0) > 2:
                img.decompose()

        # ç§»é™¤å¹²æ‰°æ ‡ç­¾
        for tag in content_div(['script', 'style', 'iframe']):
            tag.decompose()

        # å¤„ç†å¾®ä¿¡ä»£ç å—æ ¼å¼
        for pre in content_div.find_all('pre', class_=re.compile(r'code-snippet__\w+')):
            for code in pre.find_all('code', recursive=False):
                code.insert_before('\n')

        # è½¬ Markdown
        body_md = md(str(content_div), heading_style="ATX", strip=['a', 'span'])

        # ================= æ ¼å¼æ¸…ç† =================
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        body_md = re.sub(r'\n{3,}', '\n\n', body_md)

        # ç§»é™¤ç©ºæ ‡é¢˜
        body_md = re.sub(r'^###\s*\n', '', body_md, flags=re.MULTILINE)
        body_md = re.sub(r'^###\s*$', '', body_md, flags=re.MULTILINE)

        # ä¿®å¤å›¾ç‰‡è¢«é”™è¯¯åŒ…è£¹åŠ ç²—
        body_md = re.sub(r'\*\*(!\[.*?\]\([^)]+\))\*\*', r'\1', body_md)

        # ä¿®å¤åŒé‡åŠ ç²—
        body_md = re.sub(r'\*\*(.+?)\*\*\*\*(.+?)\*\*', r'**\1\2**', body_md)

        # æ¸…ç†è¿ç»­çš„åå¼•å·å—æ ‡è®°
        body_md = re.sub(r'```\s*```\n', '```\n', body_md)
        body_md = re.sub(r'```\s*```\s*```', '```', body_md)

        # ç§»é™¤ä»£ç å—å‘¨å›´å¤šä½™çš„åå¼•å·è¡Œ
        body_md = re.sub(r'\n```\n```\n', '\n```\n', body_md)

        # å†æ¬¡æ¸…ç†å¤šä½™ç©ºè¡Œ
        body_md = re.sub(r'\n{3,}', '\n\n', body_md)

        # ================= 3. ç»„è£…æœ€ç»ˆè¾“å‡º =================

        final_output = f"""# {title}

**æ¥æº**: {account}
**æ—¶é—´**: {date_str}
**é“¾æ¥**: {url}

---

{body_md}
"""
        return final_output

    except Exception as e:
        print(f"    âŒ è§£æå¼‚å¸¸: {e}")
        return None


# æµ‹è¯•å…¥å£
if __name__ == "__main__":
    # æµ‹è¯•å•ç¯‡æ–‡ç« è½¬æ¢
    test_url = "https://mp.weixin.qq.com/s/acMM1zgxUmzlrFk6O7p7iw"
    result = parse_wechat_to_md(test_url)

    if result:
        print(result[:2000])
        print("\nâœ… è½¬æ¢æˆåŠŸï¼")
