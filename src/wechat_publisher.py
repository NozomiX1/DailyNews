# DailyNews - å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒæ¨¡å—
# å°†ç”Ÿæˆçš„æ—¥æŠ¥å‘å¸ƒåˆ°è‰ç¨¿ç®±
import requests
import json
from pathlib import Path
import sys
import re
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
import config


class WeChatPublisher:
    """å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒå™¨"""

    def __init__(self, app_id=None, app_secret=None):
        self.app_id = app_id or config.APP_ID
        self.app_secret = app_secret or config.APP_SECRET
        self.token = self._get_access_token()

    def _get_access_token(self):
        """è·å– access_token"""
        url = f"https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&appid={self.app_id}&secret={self.app_secret}"
        try:
            resp = requests.get(url, proxies=getattr(config, 'PROXIES', None)).json()
            if 'access_token' in resp:
                return resp['access_token']
            else:
                raise Exception(f"è·å– access_token å¤±è´¥: {resp}")
        except Exception as e:
            raise Exception(f"è·å– access_token å¼‚å¸¸: {e}")

    def _calc_text_width(self, text):
        """è®¡ç®—æ–‡æœ¬å®½åº¦ï¼ˆä»¥ 1/3 å•ä½ä¸ºåŸºå‡†ï¼‰"""
        width = 0
        for char in text:
            if char in 'ğŸŒŸâ­ğŸ“ğŸ•’ğŸ·ï¸':
                width += 4  # emoji = 4/3å•ä½
            elif ord(char) > 127:  # ä¸­æ–‡å­—ç¬¦
                width += 3  # ä¸­æ–‡å­—ç¬¦ = 1å•ä½
            else:  # è‹±æ–‡ç©ºæ ¼ç­‰
                width += 1  # è‹±æ–‡ç©ºæ ¼ = 1/3å•ä½
        return width

    def generate_html(self, news_items):
        """
        ä»æ–°é—»åˆ—è¡¨ç”Ÿæˆ HTMLï¼ˆç´§å‡‘æ ¼å¼ï¼Œæ— å¤šä½™ç¼©è¿›ï¼‰

        Args:
            news_items: æ–°é—»åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {title, source, time, url, rating, tag, summary}

        Returns:
            HTML å­—ç¬¦ä¸²
        """
        html_parts = ['<section style="font-family: -apple-system, BlinkMacSystemFont, Arial, sans-serif;">']
        html_parts.append('<section style="margin-top: 20px;"></section>')

        for idx, item in enumerate(news_items, 1):
            # ç´§å‡‘çš„HTMLï¼Œæ— å¤šä½™ç¼©è¿›å’Œæ¢è¡Œ
            title_html = f'<h3 style="margin-top: 30px; margin-bottom: 5px; font-size: 18px; font-weight: bold; color: #000;">{idx}. {item["title"]}</h3>'

            # åŠ¨æ€è®¡ç®—å¡«å……ç©ºæ ¼ï¼Œè®©ä¸¤è¡Œçš„emojiå¯¹é½
            prefix1 = f'ğŸ“ æ¥æºï¼š{item["source"]}'
            prefix2 = f'â­ ä»·å€¼ï¼š{item["rating"]}' if item.get("rating") else ''

            width1 = self._calc_text_width(prefix1)
            width2 = self._calc_text_width(prefix2) if prefix2 else 0

            # ç”¨è‹±æ–‡ç©ºæ ¼è¡¥é½çŸ­çš„
            if width1 < width2:
                prefix1 += ' ' * (width2 - width1)
            elif width2 < width1:
                prefix2 += ' ' * (width1 - width2)

            # æ‹¼æ¥ï¼ˆå„åŠ ä¸€ä¸ªä¸­æ–‡ç©ºæ ¼åˆ†éš”ä¸‹ä¸€ä¸ªemojiï¼‰
            meta_first_line = f'{prefix1}ã€€ğŸ•’ {item["time"]}'

            meta_second_parts = []
            if item.get("rating"):
                meta_second_parts.append(prefix2)
            if item.get("tag"):
                meta_second_parts.append(f'ã€€ğŸ·ï¸ æ ‡ç­¾ï¼š{item["tag"]}')

            meta_second_line = ''
            if meta_second_parts:
                meta_second_line = '<br>' + ''.join(meta_second_parts)

            # åˆå¹¶ï¼šç¬¬ä¸€è¡Œ + ç¬¬äºŒè¡Œ + é“¾æ¥
            meta_html = f'<div style="font-size: 13px; color: #888; margin-bottom: 10px; background: #f9f9f9; padding: 8px; border-radius: 4px;">{meta_first_line}{meta_second_line}<br><span style="display: inline-block; margin-top: 4px; color: #576b95; word-break: break-all;">ğŸ”— é“¾æ¥ï¼š{item["url"]}</span></div>'

            summary_text = item["summary"].replace("\n", "<br>")
            summary_html = f'<p style="font-size: 16px; color: #333; line-height: 1.6; text-align: justify; margin-bottom: 25px;">{summary_text}</p>'

            divider = '<hr style="border: 0; border-top: 1px dashed #ddd; margin: 20px 0;" />' if idx < len(news_items) else ""
            html_parts.append(title_html + meta_html + summary_html + divider)

        html_parts.append("</section>")
        return "".join(html_parts)

    def _parse_daily_report(self, report_path):
        """
        è§£æ daily_report.md æ–‡ä»¶

        Args:
            report_path: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„

        Returns:
            è§£æåçš„æ–°é—»åˆ—è¡¨
        """
        with open(report_path, "r", encoding="utf-8") as f:
            content = f.read()

        news_items = []

        # å»æ‰å¼€å¤´çš„ header éƒ¨åˆ†ï¼Œæ‰¾åˆ° "### 1." å¼€å§‹çš„ä½ç½®
        header_end = content.find('### 1.')
        if header_end != -1:
            content = content[header_end + 6:]  # +6 è·³è¿‡ "### 1."

        # æŒ‰æ–‡ç« åˆ†å‰² (æ¯ç¯‡ä»¥ ### å¼€å¤´)
        articles = re.split(r'\n###\s+\d+\.\s+', content)

        for article in articles:
            if not article.strip():
                continue

            # æå–æ ‡é¢˜
            title_match = re.search(r'^(.+?)\n', article)
            title = title_match.group(1).strip() if title_match else "æ— æ ‡é¢˜"

            # æå–æ¥æº
            source_match = re.search(r'\*\*æ¥æº\*\*: (.+?) \|', article)
            source = source_match.group(1).strip() if source_match else "æœªçŸ¥"

            # æå–æ—¶é—´
            time_match = re.search(r'\|\s*\*\*æ—¶é—´\*\*: (.+?)\n', article)
            time_str = time_match.group(1).strip() if time_match else ""

            # æå–é“¾æ¥
            url_match = re.search(r'\*\*é“¾æ¥\*\*: (.+?)\n', article)
            url = url_match.group(1).strip() if url_match else ""

            # æå–ä»·å€¼è¯„åˆ†ï¼ˆæ¸…ç†å¯èƒ½åŒ…å«çš„æ ‡ç­¾éƒ¨åˆ†ï¼‰
            rating_match = re.search(r'\*\*ä»·å€¼\*\*: (.+?)\n', article)
            rating = rating_match.group(1).strip() if rating_match else ""
            # ç§»é™¤åé¢å¯èƒ½åŒ…å«çš„ "**æ ‡ç­¾**: xxx" éƒ¨åˆ†
            rating = re.sub(r'\s*\*\*æ ‡ç­¾\*\*:.+', '', rating).strip()

            # æå–æ ‡ç­¾
            tag_match = re.search(r'\*\*æ ‡ç­¾\*\*: (.+?)\n', article)
            tag = tag_match.group(1).strip() if tag_match else ""

            # æå–æ‘˜è¦
            summary_match = re.search(r'\*\*æ‘˜è¦\*\*: (.+?)(?:\n---|\n\n###|\Z)', article, re.DOTALL)
            summary = summary_match.group(1).strip() if summary_match else ""
            summary = re.sub(r'<br>', '\n', summary)

            if title and source:
                news_items.append({
                    'title': title,
                    'source': source,
                    'time': time_str,
                    'url': url,
                    'rating': rating,
                    'tag': tag,
                    'summary': summary
                })

        return news_items

    def publish_to_draft(self, report_path, title=None, target_date=None):
        """
        å°† daily_report.md å‘å¸ƒåˆ°è‰ç¨¿ç®±

        Args:
            report_path: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
            title: è‰ç¨¿æ ‡é¢˜ï¼Œé»˜è®¤ä¸º "AI æ¯æ—¥æƒ…æŠ¥ | YYYY-MM-DD"
            target_date: æŠ¥å‘Šæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä»Šå¤©

        Returns:
            draft_id: è‰ç¨¿ ID
        """
        # è§£ææŠ¥å‘Š
        news_items = self._parse_daily_report(report_path)

        if not news_items:
            raise Exception("âŒ æŠ¥å‘Šä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ç« ")

        print(f"ğŸ“Š è§£æåˆ° {len(news_items)} ç¯‡æ–‡ç« ")

        # ç”Ÿæˆæ ‡é¢˜
        if not title:
            if not target_date:
                target_date = datetime.now().strftime("%Y-%m-%d")
            title = f"AI æ¯æ—¥æƒ…æŠ¥ | {target_date}"

        # ç”Ÿæˆ HTML
        content_html = self.generate_html(news_items)

        # åˆ›å»ºè‰ç¨¿
        draft_id = self._create_draft(title, content_html, config.COVER_MEDIA_ID)

        return draft_id

    def _create_draft(self, title, content, thumb_id):
        """
        åˆ›å»ºè‰ç¨¿

        Args:
            title: æ–‡ç« æ ‡é¢˜
            content: æ–‡ç« å†…å®¹ (HTML)
            thumb_id: å°é¢å›¾ media_id

        Returns:
            media_id: è‰ç¨¿ ID
        """
        url = f"https://api.weixin.qq.com/cgi-bin/draft/add?access_token={self.token}"
        data = {
            "articles": [{
                "title": title,
                "author": "AI Report",
                "digest": "ä»Šæ—¥AIçƒ­ç‚¹æ‘˜è¦...",
                "content": content,
                "thumb_media_id": thumb_id
            }]
        }

        resp = requests.post(
            url,
            data=json.dumps(data, ensure_ascii=False).encode('utf-8'),
            headers={'Content-Type': 'application/json; charset=utf-8'},
            proxies=getattr(config, 'PROXIES', None)
        )

        result = resp.json()

        if 'media_id' not in result:
            raise Exception(f"âŒ è‰ç¨¿åˆ›å»ºå¤±è´¥: {result}")

        return result['media_id']


# ================= å‘½ä»¤è¡Œå…¥å£ =================

def main():
    import argparse

    parser = argparse.ArgumentParser(description="å°†æ—¥æŠ¥å‘å¸ƒåˆ°å¾®ä¿¡å…¬ä¼—å·è‰ç¨¿ç®±")
    parser.add_argument("--date", default=None, help="æŠ¥å‘Šæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä»Šå¤©")
    args = parser.parse_args()

    # ç¡®å®šæ—¥æœŸ
    target_date = args.date or datetime.now().strftime("%Y-%m-%d")

    # æŠ¥å‘Šè·¯å¾„
    report_path = config.OUTPUT_DIR / target_date / "daily_report.md"

    if not report_path.exists():
        print(f"âŒ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_path}")
        print(f"   è¯·å…ˆè¿è¡Œä»»åŠ¡æ‰§è¡ŒæŒ‡å—ä¸­çš„æ­¥éª¤ 2-3 ç”ŸæˆæŠ¥å‘Š")
        return

    print("=" * 50)
    print(f"ğŸ“¤ æ­£åœ¨å‘å¸ƒæŠ¥å‘Šåˆ°è‰ç¨¿ç®±")
    print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_path}")
    print("=" * 50)

    try:
        publisher = WeChatPublisher()
        draft_id = publisher.publish_to_draft(report_path, target_date=target_date)

        print(f"\nâœ… è‰ç¨¿åˆ›å»ºæˆåŠŸï¼")
        print(f"ğŸ“‹ Media ID: {draft_id}")
        print(f"\nğŸ‘‰ è¯·ç™»å½•å¾®ä¿¡å…¬ä¼—å·åå°æŸ¥çœ‹è‰ç¨¿ç®±")
        print("=" * 50)

    except Exception as e:
        print(f"\nâŒ å‘å¸ƒå¤±è´¥: {e}")
        print("\nå¯èƒ½çš„åŸå› :")
        print("  1. APP_ID æˆ– APP_SECRET é…ç½®é”™è¯¯")
        print("  2. COVER_MEDIA_ID æ— æ•ˆ")
        print("  3. ç½‘ç»œè¿æ¥é—®é¢˜")


if __name__ == "__main__":
    main()
