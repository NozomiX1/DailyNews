"""
Paper Fetcher - ä» HuggingFace è·å–æ¯æ—¥è®ºæ–‡æ¦œå•

ä½¿ç”¨ PaperRanker å¯¹è®ºæ–‡è¿›è¡Œè¯„åˆ†æ’åºï¼Œä¿å­˜ä¸º Markdownã€‚
"""
import os
import sys
import requests
from datetime import date, timedelta
from pathlib import Path

# æ¸…é™¤ä»£ç†ç¯å¢ƒå˜é‡ (é¿å…å½±å“ requests)
for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
    os.environ.pop(proxy_var, None)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.paper_ranker import PaperRanker

# ArXiv å¯¹çˆ¬è™«é™åˆ¶è¾ƒä¸¥ï¼Œå¿…é¡»å¸¦ User-Agent
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}


def sanitize_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    import re
    return re.sub(r'[\\/*?:"<>|]', "", name).strip()


def fetch_and_save_papers(target_date: str, max_papers: int = 20, enable_topic_bonus: bool = False) -> Path:
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„è®ºæ–‡å¹¶ä¿å­˜ä¸º Markdown

    Args:
        target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)
        max_papers: æœ€å¤šä¿å­˜è®ºæ–‡æ•°
        enable_topic_bonus: æ˜¯å¦å¯ç”¨å…´è¶£åŠ æˆ

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # 1. è·å–è®ºæ–‡åˆ—è¡¨
    print(f"[1/3] è·å–è®ºæ–‡åˆ—è¡¨: {target_date}")
    url = f"https://huggingface.co/api/daily_papers?date={target_date}"
    resp = requests.get(url, headers=HEADERS, timeout=30)

    if resp.status_code != 200:
        raise Exception(f"API è¯·æ±‚å¤±è´¥ ({resp.status_code}): {url}")

    papers = resp.json()
    if not papers:
        raise Exception(f"å½“æ—¥æ— æ•°æ®: {target_date}")

    print(f"  è·å–åˆ° {len(papers)} ç¯‡è®ºæ–‡")

    # 2. æ’åº
    print(f"\n[2/3] è®ºæ–‡æ’åº...")
    ranker = PaperRanker(enable_topic_bonus=enable_topic_bonus)
    ranked = ranker.rank_papers(papers)

    # ä¿å­˜åˆ° data/papers/ ç›®å½•
    papers_dir = Path(__file__).parent.parent / "data" / "papers"
    papers_dir.mkdir(parents=True, exist_ok=True)

    output_path = papers_dir / f"{target_date}.md"

    # 3. ç”Ÿæˆ Markdown
    print(f"\n[3/3] ä¿å­˜æ¦œå•...")
    content = f"# æ¯æ—¥è®ºæ–‡æ¦œå• - {target_date}\n\n"
    content += f"**æ—¥æœŸ**: {target_date}\n"
    content += f"**è®ºæ–‡æ•°**: {len(ranked)}\n\n"
    content += "---\n\n"

    for i, paper in enumerate(ranked[:max_papers], 1):
        title = paper.get("title", "Unknown")
        org = paper.get("organization", {}).get("fullname", "Unknown")
        score = paper.get("rank_score", 0)
        reasons = paper.get("rank_reasons", "")
        is_golden = paper.get("is_golden", False)

        paper_detail = paper.get("paper", {})
        arxiv_id = paper_detail.get("id", "")
        upvotes = paper_detail.get("upvotes", 0)
        stars = paper_detail.get("githubStars", 0)
        comments = paper.get("numComments", 0)
        summary = paper_detail.get("summary", "") or paper.get("summary", "")

        # æ ‡é¢˜è¡Œ
        golden_mark = "ğŸ†" if is_golden else ""
        content += f"### {golden_mark} {i}. {title}\n\n"

        # å…ƒä¿¡æ¯
        content += f"**arXiv ID**: {arxiv_id}\n"
        content += f"**ç»„ç»‡**: {org}\n"
        content += f"**å¾—åˆ†**: {score}\n"
        content += f"**æ ‡ç­¾**: {reasons}\n"
        content += f"**Upvotes**: {upvotes} | **Stars**: {stars} | **Comments**: {comments}\n\n"

        # æ‘˜è¦
        if summary:
            content += f"**æ‘˜è¦**: {summary[:300]}...\n\n"

        content += "---\n\n"

    output_path.write_text(content, encoding='utf-8')
    print(f"  å·²ä¿å­˜: {output_path}")

    return output_path


def main():
    import argparse

    parser = argparse.ArgumentParser(description="è·å– HuggingFace æ¯æ—¥è®ºæ–‡æ¦œå•")
    parser.add_argument("--date", default=None, help="æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤æ˜¨å¤©")
    parser.add_argument("--max-papers", type=int, default=20, help="æœ€å¤šä¿å­˜è®ºæ–‡æ•°")
    parser.add_argument("--topic-bonus", action="store_true", help="å¯ç”¨å…´è¶£åŠ æˆ")

    args = parser.parse_args()

    # é»˜è®¤æ˜¨å¤©
    target_date = args.date or (date.today() - timedelta(days=1)).strftime("%Y-%m-%d")

    print("=" * 60)
    print(f"ğŸ“Š HuggingFace æ¯æ—¥è®ºæ–‡æ¦œå•")
    print(f"ğŸ“… æ—¥æœŸ: {target_date}")
    print("=" * 60)

    try:
        output_path = fetch_and_save_papers(
            target_date,
            max_papers=args.max_papers,
            enable_topic_bonus=args.topic_bonus
        )
        print(f"\nâœ… å®Œæˆ!")
        print(f"ğŸ“„ æ–‡ä»¶: {output_path}")

    except Exception as e:
        print(f"\nâŒ å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
