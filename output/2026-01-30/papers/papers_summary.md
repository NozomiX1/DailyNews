# 每日论文汇总 - 2026-01-30

**论文数量**: 12

---

###  1. 通过词元级数据过滤塑造模型能力 (Shaping capabilities with token-level data filtering)

**论文链接**: [https://arxiv.org/abs/2601.21571](https://arxiv.org/abs/2601.21571)
**组织**: Anthropic
**得分**: 87.82
**标签**: Super Lab
**Upvotes**: 15 | **Stars**: 42

**摘要**: 本文提出在预训练阶段通过数据过滤来塑造大语言模型的能力，以解决后期微调方法易被对抗攻击绕过的问题。研究重点展示了词元级（token-level）过滤在移除特定领域能力（如医疗知识）上的优越性，相比文档级过滤，它能以更低的通用能力损失实现目标能力的精准削减。实验表明该方法具有显著的可扩展性，在大型模型上可使目标领域的推理难度增加 7000 倍，且对标注噪声表现出极强的稳健性。

**亮点**:
  - 证明了词元级过滤在预训练阶段限制模型特定能力的有效性，且比文档级过滤更具成本效益
  - 发现过滤效果随模型规模显著增强（Scaling Law），在大模型上可导致目标领域计算成本数千倍的增长
  - 提出利用稀疏自编码器（SAE）进行词元标注并蒸馏出高性能分类器的新型方法论

---

###  2. ConceptMoE：用于隐式计算分配的自适应 Token 到概念压缩 (ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation)

**论文链接**: [https://arxiv.org/abs/2601.21420](https://arxiv.org/abs/2601.21420)
**组织**: ByteDance Seed
**得分**: 83.13
**标签**: Super Lab
**Upvotes**: 28 | **Stars**: 11

**摘要**: ConceptMoE 针对大语言模型对所有 token 分配统一计算量的效率问题，提出将语义相似的 token 动态合并为“概念”表示。该方法通过可学习的分块模块识别最优边界，在进入计算密集型模型前按目标比例压缩序列，从而实现隐式的计算分配。实验表明，在相同激活 FLOPs 下，ConceptMoE 在语言理解、长文本及多模态任务上均优于标准 MoE，并显著提升了推理速度并降低了 KV 缓存占用。

**亮点**:
  - 提出自适应分块模块，通过 token 相似度实现从 token 到概念的动态压缩。
  - 在长文本理解任务上比标准 MoE 提升 2.3 个百分点，持续训练场景下增益高达 5.5 个百分点。
  - 大幅优化推理效率：R=2 时预填充速度提升 175%，解码速度提升 117%，且显著减少 KV 缓存。

---

###  3. 各就其位：评估文本生成图像模型的空间智能基准 (Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models)

**论文链接**: [https://arxiv.org/abs/2601.20354](https://arxiv.org/abs/2601.20354)
**组织**: alibaba-inc
**得分**: 72.17
**标签**: Frontier Lab
**Upvotes**: 104 | **Stars**: 97

**摘要**: 本研究针对当前文本生成图像（T2I）模型在处理复杂空间关系（如感知、推理、交互）方面的不足，提出了全新的评估基准 SpatialGenEval。该基准包含1230个信息密集的长提示词，涵盖25个现实场景及10个空间子领域，通过对21个顶尖模型的评估揭示了高阶空间推理仍是当前模型的主要瓶颈。此外，研究者还构建了包含1.54万个图文对的 SpatialT2I 数据集，通过微调显著提升了主流模型在处理空间关系时的准确性与写实性。

**亮点**:
  - 推出了涵盖10个空间维度（如遮挡、因果、布局等）的高密度提示词基准 SpatialGenEval
  - 构建了 SpatialT2I 数据集，通过重写提示词确保图像一致性并保持信息密度
  - 证明了以数据为中心的范式能有效提升 SD-XL 等模型在空间智能方面的表现

---

###  4. Qwen3-ASR 技术报告 (Qwen3-ASR Technical Report)

**论文链接**: [https://arxiv.org/abs/2601.21337](https://arxiv.org/abs/2601.21337)
**组织**: Qwen
**得分**: 66.84
**标签**: Super Lab
**Upvotes**: 21 | **Stars**: 0

**摘要**: 该报告推出了 Qwen3-ASR 系列语音识别模型（1.7B 和 0.6B）以及一款非自回归语音强制对齐模型。这些模型基于 Qwen3-Omni 基础模型开发，支持 52 种语言的语种识别与转写，并在大规模语音数据上进行了训练。实验结果显示，1.7B 版本在开源界达到 SOTA 性能且可比肩顶尖商业 API，而 0.6B 版本在保持高精度的同时实现了极高的推理效率。此外，其强制对齐模型在时间戳预测精度和通用性上均优于现有主流模型。

**亮点**:
  - 支持 52 种语言的高精度 ASR 和语种识别（LID）
  - Qwen3-ASR-1.7B 达到开源模型 SOTA 水平，性能直追闭源 API
  - 0.6B 模型极具效率优势，支持每秒处理 2000 秒音频的超高并发转录
  - 推出基于 LLM 的非自回归强制对齐模型，支持 11 种语言的高精度时间戳对齐

---

###  5. Idea2Story：将研究构想转化为完整科学叙事的自动化流程 (Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives)

**论文链接**: [https://arxiv.org/abs/2601.20833](https://arxiv.org/abs/2601.20833)
**组织**: AgentAlpha
**得分**: 58.39
**标签**: 
**Upvotes**: 140 | **Stars**: 226

**摘要**: 本文提出了 Idea2Story，一种由预计算驱动的自主科学发现框架，旨在解决现有 LLM 智能体在科研流程中因在线推理导致的高成本、上下文限制及幻觉问题。该框架核心在于将文献理解从实时推理转为离线知识构建，通过提取论文及其评审反馈中的方法论单元，构建结构化的知识图谱。在执行阶段，系统将用户意图与图谱中的既有范式对齐，实现高质量研究模式的高效检索与复用。实验表明，该方法能生成连贯、具创新性且方法论严谨的科研叙事，为可靠的自主科学发现奠定了可扩展的基础。

**亮点**:
  - 将科研发现范式从“实时在线推理”转向“离线知识图谱构建”，显著降低计算开销
  - 利用同行评审反馈辅助构建结构化的方法论知识库，提升研究模式的可靠性
  - 有效缓解了 LLM 的上下文窗口瓶颈，通过模式复用减少了端到端流程中的试错成本

---

###  6. DynamicVLA：针对动态物体操作的视觉-语言-动作模型 (DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation)

**论文链接**: [https://arxiv.org/abs/2601.22153](https://arxiv.org/abs/2601.22153)
**组织**: MMLab@NTU
**得分**: 47.43
**标签**: 
**Upvotes**: 57 | **Stars**: 72

**摘要**: DynamicVLA 是一个旨在解决视觉-语言-动作（VLA）模型在处理动态物体时感知迟钝和控制不连续问题的框架。该研究通过轻量化模型设计、连续推理机制以及潜在感知动作流技术，实现了高效的空间编码与低延迟的闭环适配。为了弥补数据空缺，作者构建了包含 20 万合成样本和 2 千真实样本的 DOM 基准数据集。实验结果表明，该模型在动态环境下的响应速度、感知精度和跨机器人泛化能力方面均有显著突破。

**亮点**:
  - 提出 0.4B 轻量化 VLA 架构，结合卷积视觉编码器实现快速且结构忠实的感知推理
  - 引入连续推理与动作流（Action Streaming）技术，通过重叠推理与执行环节大幅降低感知执行延迟
  - 构建了大规模动态物体操作 (DOM) 基准，提供自动化的合成与真实数据采集流水线

---

###  7. EEG 基础模型：进展、基准测试与挑战 (EEG Foundation Models: Progresses, Benchmarking, and Open Problems)

**论文链接**: [https://arxiv.org/abs/2601.17883](https://arxiv.org/abs/2601.17883)
**组织**: Huazhong University of Science and Technology
**得分**: 39.07
**标签**: 
**Upvotes**: 17 | **Stars**: 47

**摘要**: 本文针对脑电图（EEG）基础模型在预训练目标、预处理和评估协议上的不一致性，系统回顾了50个代表性模型并构建了统一分类框架。研究者对12个开源基础模型在13个数据集上进行了大规模基准测试，涵盖跨受试者泛化和少样本校准等真实场景。研究发现，线性探测效果普遍不足，专用模型在多项任务中仍具竞争力，且当前数据量下模型规模的增加并不一定能提升泛化性能。

**亮点**:
  - 建立了包含50个模型的EEG基础模型分类框架，涵盖数据标准化、架构和自监督策略。
  - 在13个数据集和9种BCI范式上对12个开源模型进行了首次大规模公平基准测试。
  - 挑战了模型缩放定律在当前EEG领域的适用性，发现更大规模的模型未必带来更好泛化。

---

###  8. OCRVerse：迈向端到端视觉语言模型中的全能型 OCR (OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models)

**论文链接**: [https://arxiv.org/abs/2601.21639](https://arxiv.org/abs/2601.21639)
**组织**: Unknown
**得分**: 38.17
**标签**: 
**Upvotes**: 42 | **Stars**: 19

**摘要**: 本文提出了 OCRVerse，这是首个将以文本为中心（如书籍报刊）和以视觉为中心（如网页、图表、科学绘图）的任务统一在端到端架构下的 OCR 方法。研究团队构建了大规模跨领域数据集，并创新性地采用了 SFT-RL 两阶段训练法，通过在强化学习阶段为不同领域设计个性化奖励策略，有效解决了跨领域数据的融合与格式冲突问题。实验证明，OCRVerse 在多项 OCR 任务中表现出色，达到了与顶尖开源及闭源大模型相媲美的水平。

**亮点**:
  - 首个实现文本中心与视觉中心 OCR 任务统合的端到端方法
  - 提出针对多领域特性的 SFT-RL 两阶段训练框架及个性化奖励策略
  - 在大规模跨领域数据工程基础上显著提升了复杂视觉元素的解析能力

---

###  9. 基于潜空间对抗正则化的离线偏好优化 (Latent Adversarial Regularization for Offline Preference Optimization)

**论文链接**: [https://arxiv.org/abs/2601.22083](https://arxiv.org/abs/2601.22083)
**组织**: Stanford University
**得分**: 37.25
**标签**: Frontier Lab
**Upvotes**: 10 | **Stars**: 1

**摘要**: 本文针对语言模型偏好优化中 Token 级正则化无法有效捕捉语义相似性的挑战，提出了名为 GANPO 的潜空间正则化方法。GANPO 通过对抗学习的方式最小化策略模型与参考模型内部表示之间的差异，从而提供更稳健的结构化反馈。实验证明，将该方法作为正则化项集成到现有离线偏好优化目标中，能显著提升模型在多种任务下的性能，且在应对分布偏移和噪声方面表现优异。

**亮点**:
  - 提出 GANPO 框架，利用潜空间对抗学习取代传统的 Token 级 KL 散度约束
  - 解决了语言模型优化中 Token 空间相似性与语义相似性不一致的核心痛点
  - 在分布偏移和噪声环境下展现出比传统正则化更强的鲁棒性，且计算开销极小

---

###  10. 机械可解释性数据归因：追踪大语言模型可解释单元的训练起源 (Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units)

**论文链接**: [https://arxiv.org/abs/2601.21996](https://arxiv.org/abs/2601.21996)
**组织**: Peking University
**得分**: 35.13
**标签**: Frontier Lab
**Upvotes**: 3 | **Stars**: 2

**摘要**: 本文提出了机械可解释性数据归因（MDA）框架，利用影响函数将大语言模型中的可解释回路追踪至特定的训练样本。通过在 Pythia 模型家族上的实验，研究者证实了针对性地删除或增加极少量高影响样本能显著影响可解释头的产生。研究发现 LaTeX 和 XML 等重复结构化数据是机制形成的催化剂，并为归纳头与上下文学习（ICL）之间的功能联系提供了直接的因果证据。此外，该研究提出的数据增强方案能有效加速模型回路的收敛。

**亮点**:
  - 提出 MDA 框架，实现了从微观电路机制到宏观训练数据的精确溯源。
  - 发现重复性结构化数据（如 LaTeX/XML）对模型内部可解释机制的形成具有催化作用。
  - 通过因果干预实验，证实了归纳头与上下文学习（ICL）能力之间的长期假设。
  - 提出了一种可显著加速模型电路收敛的机械式数据增强方法。

---

###  11. 探索智能体的推理奖励模型 (Exploring Reasoning Reward Model for Agents)

**论文链接**: [https://arxiv.org/abs/2601.22154](https://arxiv.org/abs/2601.22154)
**组织**: Unknown
**得分**: 34.91
**标签**: 
**Upvotes**: 19 | **Stars**: 21

**摘要**: 本文针对智能体强化学习（Agentic RL）中稀疏结果奖励无法区分中间推理质量的问题，提出了 Agent-RRM（智能体推理奖励模型）。该模型能为智能体轨迹提供包含推理轨迹、缺陷批判及过程评分的结构化反馈。研究进一步探讨了三种集成策略（Reagent-C/R/U），实验证明 Reagent-U 在 GAIA 和 WebWalkerQA 等 12 个基准测试中显著提升了性能，验证了细粒度推理反馈在复杂任务中的有效性。

**亮点**:
  - 提出 Agent-RRM 模型，通过推理追踪、针对性批判和整体评分提供多维结构化反馈。
  - 系统化探索并对比了三种不同的推理信号集成训练策略：Reagent-C、Reagent-R 和 Reagent-U。
  - 在 GAIA (43.7%) 和 WebWalkerQA (46.2%) 等高难度 benchmark 上取得了显著的性能飞跃。

---

###  12. MetricAnything：利用噪声异构数据实现度量深度预训练的规模化 (MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources)

**论文链接**: [https://arxiv.org/abs/2601.22054](https://arxiv.org/abs/2601.22054)
**组织**: Unknown
**得分**: 33.18
**标签**: 
**Upvotes**: 3 | **Stars**: 62

**摘要**: 本文提出了 MetricAnything，一个旨在解决度量深度估计中传感器噪声、相机偏差和数据歧义问题的预训练框架。该方法的核心是引入了“稀疏度量提示（Sparse Metric Prompt）”，通过随机掩码深度图作为通用接口，实现了空间推理与特定硬件偏差的有效解耦。研究利用包含 2000 万图像-深度对的大规模异构数据集进行训练，首次在度量深度领域验证了显著的规模化效应（Scaling Law），并在深度补全、单目深度估计及 3D 重建等多项任务中刷新了最前沿性能。

**亮点**:
  - 提出稀疏度量提示技术，成功解耦空间推理与传感器/相机偏差。
  - 首次在度量深度估计任务中展示了清晰的性能规模化趋势（Scaling Trend）。
  - 预训练模型能显著提升多模态大模型（MLLM）的空间智能和感知能力。
  - 在单目深度估计、相机内参恢复及 VLA 规划等多个领域均达到 SOTA 水平。

---
