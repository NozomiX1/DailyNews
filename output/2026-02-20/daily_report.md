# AI 每日情报 | 2026-02-20

## 📊 今日情报

### 1. [Isomorphic Labs] IsoDDE (AlphaFold 4): 统一药物设计引擎与闭源策略
**来源**: 新智元 | **时间**: 2026-02-20 11:00
**价值**: 🌟🌟🌟 **标签**: [发布] [AI for Science] [争议]
**链接**: https://mp.weixin.qq.com/s/b3u6WFzIyMLFvez3o4ZJcQ

> 🎯 **一句话摘要**：Isomorphic Labs 发布代称「AlphaFold 4」的 IsoDDE，在蛋白-药物交互及隐蔽位点发现上全面碾压前代，但因彻底闭源引发学界对 AI 科学工具私有化的担忧。

#### 🔹 核心技术/实现逻辑

- **统一药物设计引擎**：不同于 AlphaFold 主要关注蛋白质结构预测，IsoDDE 整合了三大核心能力——结构预测、结合强度计算以及隐蔽结合位点发现。
- **全原子级精度**：能够准确模拟药物分子（配体）与蛋白质靶点之间的相互作用，包括抗体识别和结合亲和力预测。
- **零样本泛化能力**：在「Runs N' Poses」基准测试中，针对与训练集相似度极低（0-20%）的新蛋白结构展现出极强的泛化性，表明模型可能采用了比 AF3 更新颖的架构或训练策略（具体细节未公开）。
- **端到端预测**：无需实验室提供的晶体结构作为起点，仅凭氨基酸序列即可完成从结构到亲和力的分析。

#### 📊 实验数据/关键结论

- **Runs N' Poses 基准 (低相似度 0-20%)**：IsoDDE 成功率是 AlphaFold 3 (AF3) 的 **2 倍以上**；在 60 个最难案例中，AF3 彻底失败而 IsoDDE 正确的有 17 个。
- **抗体识别能力**：IsoDDE 的高精度预测成功率是 AF3 的 **2.3 倍**，是开源模型 Boltz-2 的 **近 20 倍**。
- **结合亲和力预测**：在多项公开测试中全面超越所有 AI 方法及传统物理模拟方法（FEP），且无需实验数据作为输入。
- **隐蔽位点发现**：在 Cereblon 蛋白案例中，IsoDDE 仅用几秒钟发现了科学家耗时 **15 年** 才通过实验确认的第二个隐蔽结合位点。

#### 💡 独家洞察/局限性

- **开源时代的终结？**：IsoDDE 仅发布了 27 页的模糊技术报告，代码、论文细节、训练方法均未公开。这标志着从 DeepMind 早期的「公共品」理念向商业「护城河」策略的重大转变。
- **数据壁垒 vs 算法创新**：业界猜测 IsoDDE 的性能提升可能很大程度上得益于 Isomorphic Labs 与礼来、诺华等药企合作获得的**私有实验数据**。如果护城河建立在私有数据而非纯算法上，开源社区的追赶难度将远超 LLM 领域（因高质量生物数据不像互联网文本那样无限且公开）。
- **科学算力鸿沟**：未来最强大的科学 AI 工具可能仅服务于付费客户，这可能导致学术界与工业界在基础科研能力上的断层。

#### 🔗 相关资源

- [IsoDDE Technical Report (PDF)](https://storage.googleapis.com/isomorphiclabs-website-public-artifacts/isodde_technical_report.pdf)
- [Nature News 报道](https://www.nature.com/articles/d41586-026-00365-7)

---

### 2. [EvoMap] Agent进化网络：基于GEP协议的基因胶囊与集体记忆机制
**来源**: 量子位 | **时间**: 2026-02-20 04:54
**价值**: 🌟🌟🌟 **标签**: [发布] [Agent架构] [AI协作]
**链接**: https://mp.weixin.qq.com/s/QvmJMuYmp7UKooXaAEKfsw

> 🎯 **一句话摘要**：EvoMap 提出了一种基于“基因胶囊”的 AI 进化网络架构，通过 GEP 协议实现 Agent 间经验的跨实例遗传与协同进化，旨在解决当前 Agent 生态中的经验孤岛与重复造轮子问题。

#### 🔹 核心技术/实现逻辑

- **基因胶囊**：
  - 核心数据结构，不同于传统的代码脚本或 Skill 库，胶囊封装的是经过验证的**策略、方法论及思维链**。
  - 包含三大要素：核心策略、环境指纹（适用场景）、审计记录（验证历史与成功率）。
  - **语义化表达**：文档明确标注 `skill.md` 是给 Agent 读取的，使得 AI 可以自主解析并应用胶囊内容。

- **GEP 协议与 A2A 通信**：
  - **GEP (Genetic Evolution Protocol)**：负责将 Agent 的实战经验打包为可传输的基因胶囊。
  - **A2A (Agent-to-Agent)**：允许不同 Agent 之间直接搜索、匹配和调用胶囊，实现去中心化的经验共享。

- **三层进化机制**：
  1.  **打包**：自动将成功解决问题的关键步骤（Prompt 策略、逻辑框架）封装。
  2.  **遗传**：通过全网搜索匹配最佳实践，实现“一个学会，百万继承”。
  3.  **筛选**：基于“自然选择”法则，通过调用次数和成功率筛选优质胶囊，淘汰低质经验。

- **生态定位对比**：
  - **MCP 协议**：解决连接外部工具/数据的问题（手脚）。
  - **Skill 体系**：解决执行具体任务的问题（招式）。
  - **EvoMap**：解决智慧传承与策略积累的问题（大脑/基因）。

#### 📊 实验数据/关键结论

- **增长数据**：前作 Evolver 插件上线 10 分钟登顶 ClawHub，3 天下载量超 36,000+。
- **跨领域有效性**：案例显示游戏策划的“强语境命名”策略（基于人设生成的独特名词）被成功遗传给后端工程师的 Agent，解决了多层嵌套循环中的变量命名冲突问题。
- **接入便捷性**：无需重构 Agent，仅需一行 `curl` 命令即可接入全球网络。

#### 💡 独家洞察/局限性

- **价值闭环创新**：引入 **Credit 积分机制**，将 Agent 从单纯的“算力消耗者”转变为“价值创造者”。优质胶囊的上传者可赚取积分兑换 API 额度和算力，通过经济激励推动生态繁荣。
- **技术信任挑战**：胶囊的安全性（如注入恶意指令）和真实性验证目前主要依赖审计记录和自然选择，尚未详细提及抗攻击的具体技术手段。
- **中心化风险**：虽然强调 Agent 间协作，但 EvoMap 本身作为中心化的基因库和网络协调者，存在单点依赖风险。

#### 🔗 相关资源

- EvoMap 官网: https://evomap.ai/

---

### 3. [OpenAI/Anthropic] AI基础设施：千亿美元融资下的算力与商业化博弈
**来源**: 新智元 | **时间**: 2026-02-20 04:18
**价值**: 🌟🌟 **标签**: [快讯] [行业] [商业化]
**链接**: https://mp.weixin.qq.com/s/jg-hb6XGpF3GyBuYwCJdVA

> 🎯 **一句话摘要**：OpenAI 拟通过史上最大 1000 亿美元融资建设 10GW 级别超算（星门计划），而 Anthropic 凭借企业级市场 10 倍营收增速有望在 2026 年实现反超，标志着 AI 竞争已从模型能力延伸至资本与基础设施的全面对决。

#### 🔹 核心技术/实现逻辑
*(注：本文为行业商业快讯，不涉及具体模型架构，重点分析技术背后的基础设施演进与商业化路径)*

- **超算基础设施（Stargate 计划）**：OpenAI 计划将资金主要用于构建全球性的 AI 专属超算网络，目标容量达到 **10 吉瓦（10GW）**。这是支撑下一代模型（如 GPT-5 系列）迭代及实现 AGI 的物理基础。
- **算力资本闭环**：英伟达不仅作为硬件供应商（“卖铲子”），更直接投资 200 亿美元，形成“硬件销售+股权投资”的双重绑定，以确保在算力极度紧缺的背景下锁定大规模订单。
- **商业化路径分化**：
  - **OpenAI**：试水对话流中的深度植入式广告（如基于场景的产品推荐），试图挖掘免费用户价值，拓宽营收渠道。
  - **Anthropic**：坚持“无广告”策略，通过 **AWS** 和 **Infosys** 等渠道深耕企业级市场，利用其在安全合规（Constitutional AI 理念）的优势吸引 B 端付费客户。

#### 📊 实验数据/关键结论
- **融资与估值**：OpenAI 本轮拟融资 **1000 亿美元**，估值飙升至 **8500 亿美元**（相当于英特尔+波音+麦当劳+耐克+星巴克市值之和）。
- **营收增速对比**（基于 Epoch AI 数据拟合）：
  - **Anthropic**：年化增速 **10倍**（主要受企业端强劲需求驱动）
  - **OpenAI**：年化增速 **3.4倍**
- **市场交叉点**：若按现有指数趋势外推，Anthropic 预计在 **2026 年年中** 营收超越 OpenAI（届时两者年化营收交汇点约 430 亿美元）。
- **财务预期**：尽管营收增长，OpenAI 因巨额基建投入，预计 2026 年亏损将扩大至约 **140 亿美元**。

#### 💡 独家洞察/局限性
- **工程挑战的转移**：对技术人员而言，未来的核心壁垒不仅是 Transformer 架构的优化，更在于**万卡/十万卡集群的运维**、**网络通信瓶颈**以及**能源获取**能力。软件算法的红利正在被硬件基础设施的规模效应稀释。
- **生存模式差异**：OpenAI 走的是“高投入、高亏损、通吃”的互联网平台模式（类似亚马逊早期）；Anthropic 则更像“高毛利、高安全”的企业服务模式。两者的技术路线差异（OpenAI 追求全能，Anthropic 追求可控）正由其商业模式决定。
- **数据局限性**：文中营收预测基于数学趋势拟合（R²=0.98/0.99），未考虑模型发布节奏（如 GPT-5 突发）对市场的瞬时冲击，实际非线性波动可能极大。

#### 🔗 相关资源

- [原文链接：新智元 - 1000亿美金！OpenAI估值飙到8500亿...](https://mp.weixin.qq.com/s/jg-hb6XGpF3GyBuYwCJdVA)
- [Epoch AI Revenue Analysis](https://epoch.ai/data-insights/anthropic-openai-revenue)
- [Bloomberg Report](https://www.bloomberg.com/news/articles/2026-02-19/openai-funding-on-track-to-top-100-billion-with-latest-round?embedded-checkout=true)

---

### 4. [新智元] 行业峰会: 奥特曼与巨头预判2028年ASI降临及AGI挑战
**来源**: 新智元 | **时间**: 2026-02-20 09:00
**价值**: 🌟🌟 **标签**: [新闻] [行业] [观点]
**链接**: https://mp.weixin.qq.com/s/oqcphK3y-I-kI-SS_pNzVQ

> 🎯 **一句话摘要**：报道印度AI峰会上硅谷大佬对于ASI/AGI降临时间（2028年/5年内）的预测，以及对“锯齿状”智能、持续学习等技术瓶颈的探讨。

#### 🔹 核心技术/实现逻辑
(注：本文为行业峰会观点综述，不涉及具体源码或架构实现)

*   **ASI/AGI 路线图预测**：
    *   **OpenAI (Altman)**：预测几年内将实现 ASI（超级智能）的早期版本，其能力将超越人类高管和顶尖科学家。
    *   **Google DeepMind (Hassabis)**：认为 AGI 已“在地平线上”，未来 5 年内可能到来，其影响将是工业革命的 10 倍。
*   **AGI 的核心缺失能力**：
    *   **持续学习**：当前模型被训练后处于“冻结”状态，无法像人类一样从经验中实时学习并个性化。
    *   **长期规划**：缺乏跨越数年的复杂规划能力。
    *   **锯齿状智能**：模型表现极不均衡，在复杂任务（如数学）上表现优异，却在简单问题上犯错，缺乏一致性。
*   **未来形态**：Meta (Wang) 提出“个人超级智能”概念，即深度集成、了解用户意图且不致瘾的 AI 助手。

#### 📊 实验数据/关键结论

*   **用户增长数据**：
    *   **ChatGPT**：在印度周活用户超过 1 亿，其中 1/3 为学生。
    *   **Meta 生态**：全球日活 35 亿，印度市场超 5 亿。
*   **时间节点共识**：Altman (2028 ASI), Amodei (几年内超越人类认知), Hassabis (5年内 AGI)。

#### 💡 独家洞察/局限性

*   **内容性质辨析**：原文标注时间为“2026年”，且存在明显的事实性错误（如将 Scale AI 创始人 Alexandr Wang 误称为 Meta 首席 AI 官），技术人员阅读时需注意该文可能为虚构预测或存在信息偏差，非严格的技术报告。
*   **行业趋势**：尽管巨头间存在激烈竞争（现场握手尴尬），但在“智能指数级增长”这一趋势上达成共识，且关注点正从单纯的模型性能转向治理、安全对齐及社会韧性。

#### 🔗相关资源

*   原文链接: https://mp.weixin.qq.com/s/oqcphK3y-I-kI-SS_pNzVQ

---

### 5. [Google] Gemini 3.1 Pro: 推理性能2倍提升与智能成本下探
**来源**: 量子位 | **时间**: 2026-02-20 01:25
**价值**: 🌟🌟 **标签**: [发布] [快讯] [Google] [多模态]
**链接**: https://mp.weixin.qq.com/s/_nBL4-5RtkOACa0HaNuyqg

> 🎯 **一句话摘要**：谷歌发布 Gemini 3.1 Pro，公开了「Deep Think」核心智能，推理性能较前代提升2倍，同时大幅降低了单位智能成本，向帕累托前沿推进。

#### 🔹 核心技术/实现逻辑
- **Deep Think 核心公开**：此次升级将上周发布的 Gemini 3 Deep Think 背后的核心智能整合进 Pro 版本，显著增强了推理能力。
- **多模态能力增强**：在语义理解、多模态生成（动作连贯性、色彩输出）、数据转可视化（如生成航空航天仪表盘）及「Vibe Coding」方面均有提升。
- **长上下文与知识更新**：支持 1M 上下文窗口，知识截止日期更新至 2025 年 1 月。
- **架构演进**：虽然是「.1」小版本号更新，但官方宣称在复杂结构化和多步骤提示词处理上能力大增。

#### 📊 实验数据/关键结论
- **ARC-AGI-2 基准**：验证分数达到 **77.1%**，官方推理性能为 Gemini 3 Pro 的 **2 倍**。
- **Arena 评测**：整体排名分数比 3 Pro 高出 **13 分**，文本与代码维度进步明显。
- **成本效益（Pareto Front）**：
  - **输入价格**：<200k tokens 为 $2，>200k tokens 为 $4。
  - **输出价格**：<200k tokens 为 $4，>200k tokens 为 $18。
  - **单次任务成本**：完成一次 ARC-AGI-2 任务仅需 **$0.96**（约合 ¥6.63），而 Gemini 3 Deep Think 成本是其 10 倍，性能差异却仅是个位数百分点。

#### 💡 独家洞察/局限性
- **版本号策略**：谷歌首次采用「.1」版本号，暗示了迭代速度的加快，甚至在 3 Pro 处于 Preview 阶段时就迅速推出了更强的 3.1 Pro。
- **成本-智能曲线重构**：此次发布的核心价值在于打破了传统的成本与智能的正比关系，在保持高性能的同时，将智能成本降低了数量级（相比 Deep Think）。
- **局限性**：文章主要侧重于官方演示和基准测试数据，未公开模型的具体架构细节（如参数量、MoE 配置）、训练数据配比或具体的 Loss 改进，属于典型的通稿性质，缺乏技术深度。

#### 🔗 相关资源
- [Google Blog: Gemini 3.1 Pro](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/)
- [DeepMind Models: Gemini Pro](https://deepmind.google/models/gemini/pro/)

---
